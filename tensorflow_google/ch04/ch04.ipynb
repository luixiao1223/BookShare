{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 深度学习与深层神经网路\n",
    "\n",
    "1. 深度学习就是深层神经网络的代名词\n",
    "2. 深度学习最重要的两个特性\n",
    "   + 多层\n",
    "   + 非线性\n",
    "\n",
    "## 线性模型的局限性\n",
    "\n",
    "最早的神经网络采用线性模型\n",
    "\n",
    "$$\n",
    "y=\\sum_{i}w_ix_i+b\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{(1)}=xW^{(1)},y=a^{(1)}W^{(2)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y=(xW^{(1)})W^{(2)}\\rightarrow y=x(W^{(1)}W^{(2)})=xW^{'}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  y=xW^{'}=\\left[\n",
    "      \\begin{array}{cc}\n",
    "      x_1 & x_2\n",
    "      \\end{array}\n",
    "      \\right]\\left[\n",
    "          \\begin{array}{c}\n",
    "          W_1^{'} \\\\\n",
    "  W_2^{'}\n",
    "          \\end{array}\n",
    "          \\right]=\\left[\n",
    "              \\begin{array}{cc}\n",
    "              W_{1}^{'}x_1 & W_2^{'} x_2\n",
    "              \\end{array}\n",
    "              \\right]\n",
    "$$\n",
    "\n",
    "线性模型不能解决异或问题。\n",
    "\n",
    "![异或](./xor.jpg)\n",
    "\n",
    "## 激活函数实现去线性化\n",
    "\n",
    "如何做的？\n",
    "\n",
    "![加入非线性的激活函数图](./nonlinear.png)\n",
    "\n",
    "$$\n",
    "\\begin{aligned} A_{1} &=\\left[a_{11}, a_{12}, a_{13}\\right]=f\\left(x W^{(1)}+b\\right)=f\\left(\\left[x_{1}, x_{2}\\right]\\left[\\begin{array}{ccc}{W_{1,1}^{(1)}} & {W_{1,2}^{(1)}} & {W_{1,3}^{(1)}} \\\\ {W_{2,1}^{(1)}} & {W_{2,2}^{(1)}} & {W_{2,3}^{(1)}}\\end{array}\\right]+\\left[\\begin{array}{lll}{b_{1}} & {b_{2}} & {b_{3}}\\end{array}\\right]\\right) \\\\ &=f\\left(\\left[W_{1,1}^{(1)} x_{1}+W_{2,1}^{(1)} x_{2}+b_{1}, W_{1,2}^{(1)} x_{1}+W_{2,2}^{(1)} x_{2}+b_{2}, W_{1,3}^{(1)} x_{1}+W_{2,3}^{(1)} x_{2}+b_{3}\\right]\\right) \\\\ &=\\left[f\\left(W_{1,1}^{(1)} x_{1}+W_{2,1}^{(1)} x_{2}+b_{1}\\right), f\\left(W_{1,2}^{(1)} x_{1}+W_{2,2}^{(1)} x_{2}+b_{2}\\right), f\\left(W_{1,3}^{(1)} x_{1}+W_{2,3}^{(1)} x_{2}+b_{3}\\right)\\right] \\end{aligned}\n",
    "$$\n",
    "\n",
    "常用的激活函数\n",
    "\n",
    "![常用的激活函数](./act.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "a = tf.nn.relu(tf.matmul(x,w1)+base1)\n",
    "b = tf.nn.relu(tf.matmul(a,w2)+base2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "## 多层神经网络解决异或语言\n",
    "\n",
    "感知机理论上不可以的原因？（这个可以列一个专题来讲）FIXME 参考书籍《Perceptions:An Introtudction to Computational Geometry》 MIT Press,1969\n",
    "\n",
    "![perception](./perc.png)\n",
    "\n",
    "![deep](./deep.png)\n",
    "\n",
    "可以看到通过隐藏层，我们可以抽象出更为高维的信息。这些信息就可以用来分类数据。从而得到更好的分类结果。\n",
    "\n",
    "# 损失函数\n",
    "\n",
    "## 经典损失函数\n",
    "\n",
    "\n",
    "### 分类问题\n",
    "\n",
    "神经网络如何输出多分类问题。比如3分类问题。苹果、香蕉、梨。\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{苹果}=\\left(\n",
    "    \\begin{array}{c}\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "    0\n",
    "    \\end{array}\n",
    "    \\right),\\mbox{香蕉}=\\left(\n",
    "        \\begin{array}{c}\n",
    "        0 \\\\\n",
    "        1 \\\\\n",
    "        0\n",
    "        \\end{array}\n",
    "        \\right),\\mbox{梨}=\\left(\n",
    "            \\begin{array}{c}\n",
    "            0 \\\\\n",
    "            0 \\\\\n",
    "            1\n",
    "            \\end{array}\n",
    "            \\right)\n",
    "$$\n",
    "\n",
    "如何比较输出值与预期值之间的差距？ *交叉熵*。\n",
    "\n",
    "交叉熵是用来衡量两个概率分布之间的距离的函数。它是分类问题中比较常见的损失函数。其定义为\n",
    "\n",
    "$$\n",
    "H(p,q)=-\\sum_{x}p(x)log[q(x)]\n",
    "$$\n",
    "\n",
    "如何将神经网络的结果变成一个概率分布？使用softmax函数。\n",
    "\n",
    "![softchange](./softchange.png)\n",
    "\n",
    "加入神经网络的原始输出为$\\{y_1,y_2,...,y_n\\}$\n",
    "\n",
    "$$\n",
    "\\operatorname{softmax}(y)_{i}=y_{i}^{\\prime}=\\frac{e^{y i}}{\\sum_{j=1}^{n} e^{y j}}\n",
    "$$\n",
    "\n",
    "这个函数满足，概率分布的所有条件。这样就把神经网络的输出改成了一个概率分布。这样就可以计算交叉熵了。\n",
    "\n",
    "但是需要注意的一点是交叉熵并不是对称的\n",
    "\n",
    "$$\n",
    "H(p,q)\\neq H(q,p)\n",
    "$$\n",
    "\n",
    "比如我们可以这样来表述交叉熵$H(p,q)$,用q来刻画p的困哪程度。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, le-10, 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> [[2.5 2.5 3. ]\n",
      " [4.  4.5 4.5]]\n",
      "---> [0.        0.6931472 1.0986123]\n",
      "---> [[ 5. 12.]\n",
      " [21. 32.]]\n",
      "---> [[19. 22.]\n",
      " [43. 50.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    v = tf.constant([[1.0,2.0,3.0], [4.0,5.0,6.0]])\n",
    "    print(\"--->\",tf.clip_by_value(v, 2.5, 4.5).eval())\n",
    "    v = tf.constant([1.0, 2.0, 3.0])\n",
    "    print(\"--->\", tf.log(v).eval())\n",
    "    vl = tf.constant([[1.0, 2.0], [3.0 , 4.0]])\n",
    "    v2 = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "    print(\"--->\", (vl *v2).eval())\n",
    "    print(\"--->\", tf.matmul(vl , v2).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$\n",
    "\\left(\n",
    "    \\begin{array}{cc}\n",
    "    1 & 2 \\\\\n",
    "    3 & 4\n",
    "    \\end{array}\n",
    "    \\right)*\\left(\n",
    "        \\begin{array}{cc}\n",
    "        5 & 6 \\\\\n",
    "        7 & 8\n",
    "        \\end{array}\n",
    "        \\right)=\\left(\n",
    "            \\begin{array}{cc}\n",
    "            5 & 12 \\\\\n",
    "            21 & 32\n",
    "            \\end{array}\n",
    "            \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> 3.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    v = tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "    print(\"--->\", tf.reduce_mean(v).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$\n",
    "\\frac{1+2+3+4+5+6}{6}=3.5\n",
    "$$\n",
    "\n",
    "tensforlow 提供了连个合并softmax和交叉熵的公式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy= tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$y$ 代表神经网络的输出，而$y\\_$代表的标准答案。如果只有一个正确答案的分类问题中可以使用另外的一个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy= tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_, logits=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### 回归问题\n",
    "\n",
    "回归问题一般采用的损失函数未均方误差。\n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}\\left(y, y^{\\prime}\\right)=\\frac{\\sum_{i=1}^{n}\\left(y_{i}-y_{i}^{\\prime}\\right)^{2}}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mse =  tf.reduce_mean(tf.square(y_ - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 自定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "定义神经网络的相关参数和变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y-input')\n",
    "w1= tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))\n",
    "y = tf.matmul(x, w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "设置自定义的损失函数\n",
    "\n",
    "$$\n",
    "\\operatorname{Loss}\\left(y, y^{\\prime}\\right)=\\sum_{i=1}^{n} f\\left(y_{i}, y_{i}^{\\prime}\\right), \\quad f(x, y)=\\left\\{\\begin{array}{ll}{a(x-y)} & {x>y} \\\\ {b(y-x)} & {x \\leqslant y}\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 定义损失函数使得预测少了的损失大，于是模型应该偏向多的方向预测。\n",
    "loss_less = 10\n",
    "loss_more = 1\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * loss_more, (y_ - y) * loss_less))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[4. 3. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "v1 = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "v2 = tf.constant([4.0, 3.0, 2.0, 1.0])\n",
    "sess = tf.InteractiveSession()\n",
    "print(tf.greater(v1, v2) .eval()) #输出[False False True True]\n",
    "print(tf.where(tf.greater(v1, v2), v1, v2).eval()) #输出[4. 3. 3. 4.J\n",
    "sess.close ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "生成模拟数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rdm = RandomState(1)\n",
    "X = rdm.rand(128,2)\n",
    "Y = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1, x2) in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training step(s), w1 is: \n",
      "[[-0.81031823]\n",
      " [ 1.4855988 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1000 training step(s), w1 is: \n",
      "[[0.01247112]\n",
      " [2.1385448 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 2000 training step(s), w1 is: \n",
      "[[0.45567414]\n",
      " [2.1706066 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 3000 training step(s), w1 is: \n",
      "[[0.69968724]\n",
      " [1.8465308 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 4000 training step(s), w1 is: \n",
      "[[0.89886665]\n",
      " [1.2973602 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w1 is: \n",
      " [[1.019347 ]\n",
      " [1.0428089]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size) % 128\n",
    "        end = (i*batch_size) % 128 + batch_size\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            print(\"After %d training step(s), w1 is: \" % (i))\n",
    "            print(sess.run(w1), \"\\n\")\n",
    "    print(\"Final w1 is: \\n\", sess.run(w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "重新定义损失函数，使得预测多了的损失大，于是模型应该偏向少的方向预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training step(s), w1 is: \n",
      "[[-0.81031823]\n",
      " [ 1.4855988 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1000 training step(s), w1 is: \n",
      "[[-0.13337609]\n",
      " [ 1.8130922 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 2000 training step(s), w1 is: \n",
      "[[0.321903 ]\n",
      " [1.5246348]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 3000 training step(s), w1 is: \n",
      "[[0.67850214]\n",
      " [1.2529727 ]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 4000 training step(s), w1 is: \n",
      "[[0.89474  ]\n",
      " [1.0859823]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w1 is: \n",
      " [[0.9743756]\n",
      " [1.0243336]]\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.mean_squared_error(y, y_)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size) % 128\n",
    "        end = (i*batch_size) % 128 + batch_size\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            print(\"After %d training step(s), w1 is: \" % (i))\n",
    "            print(sess.run(w1), \"\\n\")\n",
    "    print(\"Final w1 is: \\n\", sess.run(w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "不同的损失函数会对训练得到的模型产生重要影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 神经网络优化算法\n",
    "\n",
    "反向传到的推导。另立专题 FIXME\n",
    "\n",
    "## 梯度下降算法\n",
    "\n",
    "$$y=x^2$$\n",
    "\n",
    "求导数\n",
    "\n",
    "$$y^{'}=2x$$\n",
    "\n",
    "那么怎么迭代到函数最低点？\n",
    "\n",
    "1. 随即取初始值比如8，学习率0.1\n",
    "2. 迭代第一次\n",
    "\n",
    "   $$6.4=8-2\\times 8 * 0.1$$\n",
    "\n",
    "3. 迭代第二次\n",
    "\n",
    "   $$5.12=6.4-2\\times 6.4 * 0.1$$\n",
    "\n",
    "4. 迭代第第三次\n",
    "\n",
    "   $$4.096=5.12-2\\times 5.12 * 0.1$$\n",
    "\n",
    "\n",
    "是这梯度下降算法的一般更新公式\n",
    "\n",
    "$$\n",
    "\\theta_{n+1}=\\theta_{n}-\\delta \\frac{\\partial J(\\theta_n)}{\\partial \\theta_n}\n",
    "$$\n",
    "\n",
    "## 共轭梯度下降算法\n",
    "\n",
    "FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "## 问题\n",
    "\n",
    "1. 可能陷入局部最优解。\n",
    "2. 数据很大时，计算所有数据的梯度非常耗时。\n",
    "3. 如何解决（随机梯度下降）\n",
    "4. 随机梯度下降，缺点可能连局部最优都找不到。\n",
    "5. 可以把数据划分为不同的batch来训练。\n",
    "\n",
    "## 学习率\n",
    "\n",
    "1. 假设我们要最小化函数  $y=x^2$, 选择初始点   $x_0=5$\n",
    "2. 学习率为1的时候，x在5和-5之间震荡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is -5.000000.\n",
      "After 2 iteration(s): x2 is 5.000000.\n",
      "After 3 iteration(s): x3 is -5.000000.\n",
      "After 4 iteration(s): x4 is 5.000000.\n",
      "After 5 iteration(s): x5 is -5.000000.\n",
      "After 6 iteration(s): x6 is 5.000000.\n",
      "After 7 iteration(s): x7 is -5.000000.\n",
      "After 8 iteration(s): x8 is 5.000000.\n",
      "After 9 iteration(s): x9 is -5.000000.\n",
      "After 10 iteration(s): x10 is 5.000000.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "TRAINING_STEPS = 10\n",
    "LEARNING_RATE = 1\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        x_value = sess.run(x)\n",
    "        print(\"After %s iteration(s): x%s is %f.\"% (i+1, i+1, x_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "学习率为0.001的时候，下降速度过慢，在901轮时才收敛到0.823355。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is 4.990000.\n",
      "After 101 iteration(s): x101 is 4.084646.\n",
      "After 201 iteration(s): x201 is 3.343555.\n",
      "After 301 iteration(s): x301 is 2.736923.\n",
      "After 401 iteration(s): x401 is 2.240355.\n",
      "After 501 iteration(s): x501 is 1.833880.\n",
      "After 601 iteration(s): x601 is 1.501153.\n",
      "After 701 iteration(s): x701 is 1.228794.\n",
      "After 801 iteration(s): x801 is 1.005850.\n",
      "After 901 iteration(s): x901 is 0.823355.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_STEPS = 1000\n",
    "LEARNING_RATE = 0.001\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        if i % 100 == 0:\n",
    "            x_value = sess.run(x)\n",
    "            print(\"After %s iteration(s): x%s is %f.\"% (i+1, i+1, x_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "使用指数衰减的学习率，在迭代初期得到较高的下降速度，可以在较小的训练轮数下取得不错的收敛程度\n",
    "\n",
    "$$\n",
    "decayed\\_learning\\_rate=learning\\_rate\\times decay\\_rate^{\\frac{global\\_step}{decay\\_steps}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is 4.000000, learning rate is 0.096000.\n",
      "After 11 iteration(s): x11 is 0.690561, learning rate is 0.063824.\n",
      "After 21 iteration(s): x21 is 0.222583, learning rate is 0.042432.\n",
      "After 31 iteration(s): x31 is 0.106405, learning rate is 0.028210.\n",
      "After 41 iteration(s): x41 is 0.065548, learning rate is 0.018755.\n",
      "After 51 iteration(s): x51 is 0.047625, learning rate is 0.012469.\n",
      "After 61 iteration(s): x61 is 0.038558, learning rate is 0.008290.\n",
      "After 71 iteration(s): x71 is 0.033523, learning rate is 0.005511.\n",
      "After 81 iteration(s): x81 is 0.030553, learning rate is 0.003664.\n",
      "After 91 iteration(s): x91 is 0.028727, learning rate is 0.002436.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_STEPS = 100\n",
    "global_step = tf.Variable(0)\n",
    "LEARNING_RATE = tf.train.exponential_decay(0.1, global_step, 1, 0.96, staircase=True)\n",
    "\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        if i % 10 == 0:\n",
    "            LEARNING_RATE_value = sess.run(LEARNING_RATE)\n",
    "            x_value = sess.run(x)\n",
    "            print(\"After %s iteration(s): x%s is %f, learning rate is %f.\"% (i+1, i+1, x_value, LEARNING_RATE_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "staircase 的作用\n",
    "\n",
    "![staricase](./stair.png)\n",
    "\n",
    "一般来说初始学习率、衰减系数和衰减速度都是根据经验设置的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 神经网络进一步优化\n",
    "\n",
    "## 过拟合问题\n",
    "\n",
    "![overfit](./overfit.png)\n",
    "\n",
    "如何解决过拟合问题？引入正则化。正则化的思想就是在损失函数中加入刻画模型复杂程度的指标。\n",
    "\n",
    "引入正则化只是，我们的优化不再是针对$J(\\theta)$,而是$J(\\theta)+\\lambda R(w)$,其中$R(w),刻画的是模型的复杂程度.\n",
    "\n",
    "1. L1 正则化\n",
    "\n",
    "$$\n",
    "R(w)=\\|w\\|_{1}=\\sum\\left|w_{i}\\right|\n",
    "$$\n",
    "\n",
    "2. L2 正则化\n",
    "\n",
    "$$\n",
    "R(w)=\\|w\\|_{2}^{2}=\\sum_{i}\\left|w_{i}^{2}\\right|\n",
    "$$\n",
    "\n",
    "### 两个正则化公式的特点。\n",
    "\n",
    "1. L1可以使得参数更稀疏。也就是说有很多参数可能会编程0.\n",
    "2. L2则不会。因为$0.01^2$后变得很小。对优化几乎没有贡献，参数不会那么快趋近于0.\n",
    "3. L1不可导，L2可导。\n",
    "\n",
    "### 实践中结合两种优化方式\n",
    "\n",
    "$$\n",
    "R(w)=\\sum_{i} \\alpha\\left|w_{i}\\right|+(1-\\alpha) w_{i}^{2}\n",
    "$$\n",
    "\n",
    "### 举例子\n",
    "\n",
    "1. 生成模拟数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "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\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "np.random.seed(0)\n",
    "\n",
    "# 以原点为圆心，半径为1的圆把散点划分成红蓝两部分，并加入随机噪音。\n",
    "for i in range(150):\n",
    "    x1 = np.random.uniform(-1,1)\n",
    "    x2 = np.random.uniform(0,2)\n",
    "    if x1**2 + x2**2 <= 1:\n",
    "        data.append([np.random.normal(x1, 0.1),np.random.normal(x2,0.1)])\n",
    "        label.append(0)\n",
    "    else:\n",
    "        data.append([np.random.normal(x1, 0.1), np.random.normal(x2, 0.1)])\n",
    "        label.append(1)\n",
    "\n",
    "data = np.hstack(data).reshape(-1,2)\n",
    "#label = np.hstack(label).reshape(-1, 1)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], c=label,\n",
    "            cmap=\"RdBu\", vmin=-.2, vmax=1.2, edgecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "2. 定义一个获取权重，并自动加入正则项到损失的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_weight(shape, lambda1):\n",
    "    var = tf.Variable(tf.random_normal(shape), dtype=tf.float32)\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(var))\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "3. 定义神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "sample_size = len(data)\n",
    "\n",
    "# 每层节点的个数\n",
    "layer_dimension = [2,10,5,3,1]\n",
    "\n",
    "n_layers = len(layer_dimension)\n",
    "\n",
    "cur_layer = x\n",
    "in_dimension = layer_dimension[0]\n",
    "\n",
    "# 循环生成网络结构\n",
    "for i in range(1, n_layers):\n",
    "    out_dimension = layer_dimension[i]\n",
    "    weight = get_weight([in_dimension, out_dimension], 0.003)\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[out_dimension]))\n",
    "    cur_layer = tf.nn.elu(tf.matmul(cur_layer, weight) + bias)\n",
    "    in_dimension = layer_dimension[i]\n",
    "\n",
    "y= cur_layer\n",
    "\n",
    "# 损失函数的定义。\n",
    "mse_loss = tf.reduce_sum(tf.pow(y_ - y, 2)) / sample_size\n",
    "tf.add_to_collection('losses', mse_loss)  #集合的概念\n",
    "loss = tf.add_n(tf.get_collection('losses'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "4. 训练不带正则项的损失函数mse_loss。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (150,) for Tensor 'Placeholder_7:0', which has shape '(?, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-75c62200ca21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After %d steps, mse_loss: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1149\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1150\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (150,) for Tensor 'Placeholder_7:0', which has shape '(?, 1)'"
     ]
    }
   ],
   "source": [
    "# 定义训练的目标函数mse_loss，训练次数及训练模型\n",
    "train_op = tf.train.AdamOptimizer(0.001).minimize(mse_loss)\n",
    "TRAINING_STEPS = 40000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op, feed_dict={x: data, y_: label})\n",
    "        if i % 2000 == 0:\n",
    "            print(\"After %d steps, mse_loss: %f\" % (i,sess.run(mse_loss, feed_dict={x: data, y_: label})))\n",
    "\n",
    "    # 画出训练后的分割曲线\n",
    "    xx, yy = np.mgrid[-1.2:1.2:.01, -0.2:2.2:.01]\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    probs = sess.run(y, feed_dict={x:grid})\n",
    "    probs = probs.reshape(xx.shape)\n",
    "\n",
    "#plt.scatter(data[:,0], data[:,1], c=label, cmap=\"RdBu\", vmin=-.2, vmax=1.2, edgecolor=\"white\")\n",
    "#plt.contour(xx, yy, probs, levels=[.5], cmap=\"Greys\", vmin=0, vmax=.1)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "5. 训练带正则项的损失函数loss。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 定义训练的目标函数loss，训练次数及训练模型\n",
    "train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "TRAINING_STEPS = 40000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op, feed_dict={x: data, y_: label})\n",
    "        if i % 2000 == 0:\n",
    "            print(\"After %d steps, loss: %f\" % (i, sess.run(loss, feed_dict={x: data, y_: label})))\n",
    "\n",
    "    # 画出训练后的分割曲线\n",
    "    xx, yy = np.mgrid[-1:1:.01, 0:2:.01]\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    probs = sess.run(y, feed_dict={x:grid})\n",
    "    probs = probs.reshape(xx.shape)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], c=label,\n",
    "            cmap=\"RdBu\", vmin=-.2, vmax=1.2, edgecolor=\"white\")\n",
    "plt.contour(xx, yy, probs, levels=[.5], cmap=\"Greys\", vmin=0, vmax=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 滑动平均模型\n",
    "\n",
    "$$\n",
    "\\text { shadow_variable }=\\text { decay } \\times \\text { shadow}_{-} \\text {variable}+(1-\\text { decay }) \\times \\text { variable }\n",
    "$$\n",
    "\n",
    "$$\n",
    "decay=\\min \\left\\{\\operatorname{decay}, \\frac{1+\\operatorname{num}_{-} \\text {updates }}{10+\\operatorname{num}_{-} \\text {updates }}\\right\\}\n",
    "$$\n",
    "\n",
    "1. 定义变量及滑动平均类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v1 = tf.Variable(0, dtype=tf.float32)\n",
    "step = tf.Variable(0, trainable=False)\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "maintain_averages_op = ema.apply([v1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "2. 查看不同迭代中变量取值的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # 初始化\n",
    "    # 初始化之后变 v1=0,v1的滑动平均为0\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "\n",
    "    # 更新变量v1的取值\n",
    "    # 更新vl的消Z)IJ平均值。衰减率为min{0.99, (1+step)/(10+step)= 0.1)=0.l,\n",
    "    # 所以 vl 的滑动平均会被更新为 0.1×0+0.9×5=4.5\n",
    "    sess.run(tf.assign(v1, 5))\n",
    "    sess.run(maintain_averages_op)\n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "\n",
    "    # 更新step和v1的取值\n",
    "    # 更新 v1 的滑动平均值。衰减率为 rnin{0.99, (1+step)/(10+step)=0.999}=0 . 99 ,\n",
    "    # 所以 v1 的滑动平均会被更新为 0.99x4.5+0.01x10=4.555。\n",
    "    sess.run(tf.assign(step, 10000))\n",
    "    sess.run(tf.assign(v1, 10))\n",
    "    sess.run(maintain_averages_op)\n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "\n",
    "    # 更新一次v1的滑动平均值\n",
    "    # 再次更新滑动平均值，得到的新滑动平均值为 0.99×4.555+0.01xl0=4.60945\n",
    "    sess.run(maintain_averages_op)\n",
    "    print sess.run([v1, ema.average(v1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "ch04.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
