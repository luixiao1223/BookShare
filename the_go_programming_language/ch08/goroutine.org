#+TITLE: Goroutine

* goroutine

1. goroutine和线程之间再数量上有很大的区别 fixme （9.8节）
2. main函数其实就是一个goroutine，我们把它称作主goroutine.

#+BEGIN_SRC go
  f()
  go f()
#+END_SRC

我们先来看看一个具体的例子

#+BEGIN_SRC go
   func main() {
    go spinner(100 * time.Millisecond)
    const n = 45
    fibN := fib(n) // slow
    fmt.Printf("\rFibonacci(%d) = %d\n", n, fibN)
  }

  func spinner(delay time.Duration) {
    for {
      for _, r := range `-\|/` {
        fmt.Printf("\r%c", r)
        time.Sleep(delay)
      }
    }
  }

  func fib(x int) int {
    if x < 2 {
      return x
    }
    return fib(x-1) + fib(x-2)
  }
#+END_SRC

** 注意

1. main 函数退出的时候，所有goroutine全部暴力退出
2. 没有程序化的方法让一个goroutine来终止另一个goroutine

* 并发时钟服务器

** clock1
#+BEGIN_SRC go
  func main() {
    listener, err := net.Listen("tcp", "localhost:8000")
    if err != nil {
      log.Fatal(err)
    }
    for {
      conn, err := listener.Accept()
      if err != nil {
        log.Print(err) // e.g., connection aborted
        continue
      }
      handleConn(conn) // handle one connection at a time
    }
  }

  func handleConn(c net.Conn) {
    defer c.Close()
    for {
      _, err := io.WriteString(c, time.Now().Format("15:04:05\n"))
      if err != nil {
        return // e.g., client disconnected
      }
      time.Sleep(1 * time.Second)
    }
  }
  //!-
#+END_SRC

当服务器打开后，可以使用
#+BEGIN_SRC sh
  nc localhost 8000
#+END_SRC
连接，但是只能允许1个客户端连接。

** netcat1

#+BEGIN_SRC go
  func main() {
    conn, err := net.Dial("tcp", "localhost:8000")
    if err != nil {
      log.Fatal(err)
    }
    defer conn.Close()
    mustCopy(os.Stdout, conn)
  }
  func mustCopy(dst io.Writer, src io.Reader) {
    if _, err := io.Copy(dst, src); err != nil {
      log.Fatal(err)
    }
  }
#+END_SRC

** clock2

可以接受多个客户端连接

#+BEGIN_SRC go
  func handleConn(c net.Conn) {
    defer c.Close()
    for {
      _, err := io.WriteString(c, time.Now().Format("15:04:05\n"))
      if err != nil {
        return // e.g., client disconnected
      }
      time.Sleep(1 * time.Second)
    }
  }

  func main() {
    listener, err := net.Listen("tcp", "localhost:8000")
    if err != nil {
      log.Fatal(err)
    }
    //!+
    for {
      conn, err := listener.Accept()
      if err != nil {
        log.Print(err) // e.g., connection aborted
        continue
      }
      go handleConn(conn) // handle connections concurrently
    }
  }
#+END_SRC

* 并发回声服务器
** reverb1
#+BEGIN_SRC go
  func echo(c net.Conn, shout string, delay time.Duration) {
    fmt.Fprintln(c, "\t", strings.ToUpper(shout))
    time.Sleep(delay)
    fmt.Fprintln(c, "\t", shout)
    time.Sleep(delay)
    fmt.Fprintln(c, "\t", strings.ToLower(shout))
  }

  func handleConn(c net.Conn) {
    input := bufio.NewScanner(c)
    for input.Scan() {
      echo(c, input.Text(), 1*time.Second)
    }
    // NOTE: ignoring potential errors from input.Err()
    c.Close()
  }

  func main() {
    l, err := net.Listen("tcp", "localhost:8000")
    if err != nil {
      log.Fatal(err)
    }
    for {
      conn, err := l.Accept()
      if err != nil {
        log.Print(err) // e.g., connection aborted
        continue
      }
      go handleConn(conn)
    }
  }
#+END_SRC
注意所有的返回是按顺序的，

#+BEGIN_SRC sh
  some
      SOME
  GOOD
      some
      some
      GOOD
      good
      good
#+END_SRC

** reverb2

#+BEGIN_SRC go
  func echo(c net.Conn, shout string, delay time.Duration) {
    fmt.Fprintln(c, "\t", strings.ToUpper(shout))
    time.Sleep(delay)
    fmt.Fprintln(c, "\t", shout)
    time.Sleep(delay)
    fmt.Fprintln(c, "\t", strings.ToLower(shout))
  }

  func handleConn(c net.Conn) {
    input := bufio.NewScanner(c)
    for input.Scan() {
      go echo(c, input.Text(), 1*time.Second)
    }
    // NOTE: ignoring potential errors from input.Err()
    c.Close()
  }

  func main() {
    l, err := net.Listen("tcp", "localhost:8000")
    if err != nil {
      log.Fatal(err)
    }
    for {
      conn, err := l.Accept()
      if err != nil {
        log.Print(err) // e.g., connection aborted
        continue
      }
      go handleConn(conn)
    }
  }
#+END_SRC

返回是乱序的，因为并发返回

#+BEGIN_SRC sh
  some
     SOME
  good
     GOOD
     some
     good
     some
     good
#+END_SRC

* 通道

1. 用来在 goroutine 之间进行通信用的。
2. 通道是引用类型。
3. 通道类型之间可以比较 $==$, 通道的0值为nil

#+BEGIN_SRC go
  ch := make(chan int)
  ch <- x
  x = <- ch
  <-ch
  close(ch)
#+END_SRC

1. 往一个关闭的通道发送数据，将引发宕机。
2. 从一个关闭的通道获取数据，会不断的获取数据。直到获取完毕所有数据。然后，之后的操作立即返回nil。
3. 重复关闭一个通道也会引发宕机。

#+BEGIN_SRC go
  ch = make(chan int)     // 无缓冲通道
  ch = make(chan int, 0)  // 无缓冲通道
  ch = make(chan init, 3) // 容量为3的通道
#+END_SRC

** 无缓冲通道

1. 无缓冲通道也叫做同步通道。

#+BEGIN_SRC go
  func main() {
    conn, err := net.Dial("tcp", "localhost:8000")
    if err != nil {
      log.Fatal(err)
    }
    done := make(chan struct{})
    go func() {
      io.Copy(os.Stdout, conn) // NOTE: ignoring errors
      log.Println("done")
      done <- struct{}{} // signal the main goroutine
    }()
    mustCopy(conn, os.Stdin)//注意主程序只执行到这一步，就卡住了。
    conn.Close()
    <-done // wait for background goroutine to finish
  }

  func mustCopy(dst io.Writer, src io.Reader) {
    if _, err := io.Copy(dst, src); err != nil {
      log.Fatal(err)
    }
  }
#+END_SRC

等待计算结果

#+BEGIN_SRC go
  package main
  import (
    "fmt"
    "time"
  )
  func main() {
    result := 0
    done := make(chan struct{})
    go func() {
      for i := 1; i < 10; i++ {
        result = i + result
        time.Sleep(1000 * time.Millisecond)
        fmt.Println(".....")
      }
      done <- struct{}{}
    }()
    <-done
    fmt.Println(result)
  }
#+END_SRC

** 管道
*** pipeline1
#+BEGIN_SRC go
  func main() {
    naturals := make(chan int)
    squares := make(chan int)

    // Counter
    go func() {
      for x := 0; ; x++ {
        naturals <- x
      }
    }()

    // Squarer
    go func() {
      for {
        x := <-naturals
        squares <- x * x
      }
    }()

    // Printer (in main goroutine)
    for {
      fmt.Println(<-squares)
    }
  }
#+END_SRC

*** pipeline2
#+BEGIN_SRC go
  func main() {
    naturals := make(chan int)
    squares := make(chan int)

    // Counter
    go func() {
      for x := 0; x < 100; x++ {
        naturals <- x
      }
      close(naturals)
    }()

    // Squarer
    go func() {
      for x := range naturals {
        squares <- x * x
      }
      close(squares)
    }()

    // Printer (in main goroutine)
    for x := range squares {
      fmt.Println(x)
    }
  }
#+END_SRC

1. 关闭每一个通道不是必须的。
2. 通道的关闭是通过是否可以访问来确定是否资源回收。而不是是否关闭

** 单项通道类型

#+BEGIN_SRC go
  func counter(out chan<- int) {
    for x := 0; x < 100; x++ {
      out <- x
    }
    close(out)
  }

  func squarer(out chan<- int, in <-chan int) {
    for v := range in {
      out <- v * v
    }
    close(out)
  }

  func printer(in <-chan int) {
    for v := range in {
      fmt.Println(v)
    }
  }

  func main() {
    naturals := make(chan int)
    squares := make(chan int)

    go counter(naturals)
    go squarer(squares, naturals)
    printer(squares)
  }
#+END_SRC

** 缓冲通道

#+BEGIN_SRC go
  ch := make(chan string, 3)
  fmt.Println(cap(ch)) // 3
  fmt.Println(len(ch)) // 2 当前有多少个元素在里面
#+END_SRC

1. 注意不能把管道当做队列来用。因为使用队列来用少有不甚，会导致程序卡住。

#+BEGIN_SRC go
  func mirroredQuery() string {
    responses := make(chan string, 3)
    go func() {responses <- request("asia.gopl.io")} ()
    go func() {responses <- request("europe.gopl.io")} ()
    go func() {responses <- request("americas.gopl.io")} ()
    return <-responses
  }

  func request(hostname string) (response string) {/* ... */}
#+END_SRC

1. 如果采用无缓冲的chan，那么慢的两个goroutine就会卡卡住。不会被释放掉，因为没有东西来接收这两goroutine的返回。
2. 具体是怎么泄露的？ fixme

* 并行循环

无并行程序写法
#+BEGIN_SRC go
  func makeThumbnails(filenames []string) {
    for _, f := range filenames {
      if _, err := thumbnail.ImageFile(f); err != nil {
        log.Println(err)
      }
    }
  }
#+END_SRC

并行写法
#+BEGIN_SRC go
  func makeThumbnails(filenames []string) {
    for _, f := range filenames {
      go thumbnail.ImageFile(f) // 这个地方存在问题，程序又错误！！！
    }
  }
#+END_SRC

上面的程序有两个地方存在问题。

1. f的问题
2. 程序运行之后瞬间推出。并没有任何函数再等待goroutine运行完毕。

#+BEGIN_SRC go
  func makeThumbnails(filenames []string){
    ch := make(chan struct{})
    for _, f : range filenames {
      go func(f string) {
        thumbnail.ImageFile(f)
        ch <-struct{}{}
      }(f)
    }

    for range filenames {
      <-ch
    }
  }
#+END_SRC

处理返回值

#+BEGIN_SRC go
  func makeThumbnails(filenames []string) error{
    errors := make(chan error)
    for _, f := range filenames {
      _, err := thumbnail.ImageFile(f)
      errors <- err
    }(f)

    for range filenames {
      if err := <-errors; err != nil {
        return err // 这里不正确，goroutine泄露危险
      }
    }

    return nil
  }
#+END_SRC

Q:为什么会造成goroutine协奏，goroutine泄露的原理是什么？

解决方案，是开辟一个和filenames一样长的通道。
#+BEGIN_SRC go
  func makeThumbnails5(filenames []string) (thumbfiles []string, err error) {
    type item struct {
      thumbfile string
      err       error
    }
    ch := make(chan item, len(filenames))
    for _, f := range filenames {
      go func(f string) {
        var it item
        it.thumbfile, it.err = thumbnail.ImageFile(f)
        ch <- it
        }(f)
    }
    for range filenames {
      it := <-ch
      if it.err != nil {
        return nil, it.err
      }
      thumbfiles = append(thumbfiles, it.thumbfile)
    }
    return thumbfiles, nil
  }
#+END_SRC

一个更好的解决方案

#+BEGIN_SRC go
  func makeThumbnails6(filenames <-chan string) int64 {
    sizes := make(chan int64)
    var wg sync.WaitGroup // number of working goroutines
    for f := range filenames {
      wg.Add(1)
      // worker
      go func(f string) {
        defer wg.Done()
        thumb, err := thumbnail.ImageFile(f)
        if err != nil {
          log.Println(err)
          return }
        info, _ := os.Stat(thumb) // OK to ignore error
        sizes <- info.Size()
      }(f)
    }
    // closer
    go func() {
      wg.Wait()
      close(sizes)
    }()
    var total int64
    for size := range sizes {
      total += size
    }
    return total
  }
#+END_SRC

* 并发的Web爬虫

** 第一版

#+BEGIN_SRC go
  func crawl(url string) []string {
    fmt.Println(url)
    list, err := links.Extract(url)
    if err != nil {
      log.Print(err)
    }
    return list
  }
#+END_SRC

#+BEGIN_SRC go
  func main() {
    worklist := make(chan []string)
    // Start with the command-line arguments.
    go func() { worklist <- os.Args[1:] }()
    // Crawl the web concurrently.
    seen := make(map[string]bool)
    for list := range worklist { // 注意，不会结束的原因在这里。因为阻塞住了。当worklist中的内容为空时。阻塞住。
      for _, link := range list {
        if !seen[link] {
          seen[link] = true
          go func(link string){
            worklist <- crawl(link)
          }(link)
        }
      }
    }
  }
#+END_SRC

问题：

1. 打开太多的链接。并发度太高，导致文件描述符不够用
2. 程序并没有终止。

** 解决链接太多问题

#+BEGIN_SRC go
  var tokens = make(chan struct{}, 20)
  func crawl(url string) []string {
    fmt.Println(url)
    tokens <- struct{}{} // acquire a token
    list, err := links.Extract(url) // 最多只有20个go线程在获取url对应的所有链接。
    <-tokens // release the token
    if err != nil {
      log.Print(err)
    }
    return list
  }
#+END_SRC

** 解决终止问题

#+BEGIN_SRC go
  func main() {
    worklist := make(chan []string)
    var n int // number of pending sends to worklist
    // Start with the command-line arguments.
    n++
    go func() { worklist <- os.Args[1:] }()
    // Crawl the web concurrently.
    seen := make(map[string]bool)
    for ; n > 0; n-- {
      list := <-worklist
      for _, link := range list {
        if !seen[link] {
          seen[link] = true
          n++
          go func(link string) {
            worklist <- crawl(link)
          }(link)
        }
      }
    }
  }
#+END_SRC

** 一个替代方案
*解决连接数过多, 没有解决终止问题？*

#+BEGIN_SRC go
  func main() {
    worklist := make(chan []string)  // lists of URLs, may have duplicates
    unseenLinks := make(chan string) // de-duplicated URLs
    // Add command-line arguments to worklist.
    go func() { worklist <- os.Args[1:] }()
    // Create 20 crawler goroutines to fetch each unseen link.
    for i := 0; i < 20; i++ {
      go func() {
        for link := range unseenLinks {
          foundLinks := crawl(link)
          go func() { worklist <- foundLinks }()
        }
      }() 
    }
    // The main goroutine de-duplicates worklist items
    // and sends the unseen ones to the crawlers.
    seen := make(map[string]bool)
    for list := range worklist {
      for _, link := range list {
        if !seen[link] {
          seen[link] = true
          unseenLinks <- link
        }
      }
    }
  }
#+END_SRC

* 多路select
** 倒计时程序
倒计时发射程序

#+BEGIN_SRC go
  func main() {
    fmt.Println("Commencing countdown.")
    tick := time.Tick(1 * time.Second)
    for countdown := 10; countdown > 0; countdown-- {
      fmt.Println(countdown)
      <-tick
    }
    launch()
  }
#+END_SRC

取消发射程序
#+BEGIN_SRC go
  abort := make(chan struct{})
  go func() {
    os.Stdin.Read(make([]byte, 1)) // read a single byte
    abort <- struct{}{}
  }()
#+END_SRC

如何同时接收并处理tick和abort消息？select

#+BEGIN_SRC go
  select {
       case <-ch1:
           // ...
       case x := <-ch2:
           // ...use x...
       case ch3 <- y:
           // ...
       default:
    // ...
  }
#+END_SRC

最终实现
#+BEGIN_SRC go
  func main() {
    // ...create abort channel...
    fmt.Println("Commencing countdown.  Press return to abort.")
    select {
    case <-time.After(10 * time.Second):
      // Do nothing.
    case <-abort:
      fmt.Println("Launch aborted!")
      return 
      }
    launch()
  }
#+END_SRC

** 注意事项
*** 多个 chan 同时有数据的时候怎么办？

随即选择一个执行

*** goroutine泄露

#+BEGIN_SRC go
  func main() {
    // ...create abort channel...
    fmt.Println("Commencing countdown.  Press return to abort.")
    tick := time.Tick(1 * time.Second)// 行为类似创建一个goroutine不断的向tick发送事件
    for countdown := 10; countdown > 0; countdown-- {
      fmt.Println(countdown)
      select {
      case <-tick:
        // Do nothing.
      case <-abort:
        fmt.Println("Launch aborted!")
        return // 返回之后，tick没有对象去取事件，但是却有一个goroutine再不断的发事件给tick.所以goroutine泄露
      }
    }
    launch()
  }
#+END_SRC

记得关闭它
#+BEGIN_SRC go
  ticker := time.NewTicker(1 * time.Second)
  <-ticker.C // receive from the ticker's channel
  ticker.Stop() // cause the ticker's goroutine to terminate
#+END_SRC

*** 非阻塞信道

#+BEGIN_SRC go
  select {
  case <-abort:
    fmt.Printf("Launch aborted!\n")
    return
  default:
    // do nothing
  }
#+END_SRC

*** nil chan

网nil chan发送或者接受数据都是永久阻塞。

#+BEGIN_SRC go
  nil <- "some" // 发送
  <- nil        // 接受
#+END_SRC

* 并发目录遍历
** 第一版
#+BEGIN_SRC go
  // walkDir recursively walks the file tree rooted at dir
  // and sends the size of each found file on fileSizes.
  func walkDir(dir string, fileSizes chan<- int64) {
    for _, entry := range dirents(dir) {
      if entry.IsDir() {
        subdir := filepath.Join(dir, entry.Name())
        walkDir(subdir, fileSizes)
      }else {
        fileSizes <- entry.Size()
      }
    }
  }
  // dirents returns the entries of directory dir.
  func dirents(dir string) []os.FileInfo {
    entries, err := ioutil.ReadDir(dir)
    if err != nil {
      fmt.Fprintf(os.Stderr, "du1: %v\n", err)
      return nil
    }
    return entries
  }
#+END_SRC

#+BEGIN_SRC go
  func main() {
    // Determine the initial directories.
    flag.Parse()
    roots := flag.Args()
    if len(roots) == 0 {
      roots = []string{"."}
    }
    // Traverse the file tree.
    fileSizes := make(chan int64)
    go func() {
      for _, root := range roots {
        walkDir(root, fileSizes)
      }
      close(fileSizes)
    }()
    // Print the results.
    var nfiles, nbytes int64
    for size := range fileSizes {
      nfiles++
      nbytes += size
    }
    printDiskUsage(nfiles, nbytes)
  }

  func printDiskUsage(nfiles, nbytes int64) {
    fmt.Printf("%d files  %.1f GB\n", nfiles, float64(nbytes)/1e9)
  }
#+END_SRC

** 改进版
*** 每隔一段时间输出信息
参数v控制是否输出filesize，每隔一段时间输出
#+BEGIN_SRC go
  var verbose = flag.Bool("v", false, "show verbose progress messages")
  func main() {
    // ...start background goroutine...
    // Print the results periodically.
    var tick <-chan time.Time
    if *verbose {
      tick = time.Tick(500 * time.Millisecond)
    }
    var nfiles, nbytes int64
  loop:
    for {
      select {
      case size, ok := <-fileSizes:
        if !ok {
          break loop // fileSizes was closed
        }
        nfiles++
        nbytes += size
      case <-tick: // 有么有goroutine泄露？
        printDiskUsage(nfiles, nbytes)
      }
    }
    printDiskUsage(nfiles, nbytes) // final totals
  }
#+END_SRC

*** 充分利用好并发

#+BEGIN_SRC go
  func main() {
    // ...determine roots...
    // Traverse each root of the file tree in parallel.
    fileSizes := make(chan int64)
    var n sync.WaitGroup
    for _, root := range roots {
      n.Add(1)
      go walkDir(root, &n, fileSizes)
    }
    go func() {
      n.Wait()
      close(fileSizes)
    }()
    // ...select loop... 上一个例子的信息输出循环
  }

  func walkDir(dir string, n *sync.WaitGroup, fileSizes chan<- int64) {
    defer n.Done()
    for _, entry := range dirents(dir) {
      if entry.IsDir() {
        n.Add(1)
        subdir := filepath.Join(dir, entry.Name())
        go walkDir(subdir, n, fileSizes)
      } else {
        fileSizes <- entry.Size()
      }
    }
  }
#+END_SRC

*** 限制上一个例子的并发量

#+BEGIN_SRC go
  // sema is a counting semaphore for limiting concurrency in dirents.
  var sema = make(chan struct{}, 20)
  // dirents returns the entries of directory dir.
  func dirents(dir string) []os.FileInfo {
    sema <- struct{}{}        // acquire token
    defer func() { <-sema }() // release token
    // ...
  }
#+END_SRC

* 取消

#+BEGIN_SRC go
  var done = make(chan struct{})
  func cancelled() bool {
    select {
    case <-done:
      return true
    default:
      return false
    }
  }
#+END_SRC

#+BEGIN_SRC go
  // Cancel traversal when input is detected.
  go func() {
    os.Stdin.Read(make([]byte, 1)) // read a single byte
    close(done)
  }()
#+END_SRC

#+BEGIN_SRC go
  for {
    select {
    case <-done: // 为什么多个地方有这个语句？ 因为在一个关闭的通道上取东西，直接返回
      // Drain fileSizes to allow existing goroutines to finish.
      for range fileSizes {
        // Do nothing.
      }
      return
    case size, ok := <-fileSizes:
      // ...
    }
  }
#+END_SRC

goroutine各自分别退出自己。
#+BEGIN_SRC go
  func walkDir(dir string, n *sync.WaitGroup, fileSizes chan<- int64) {
    defer n.Done()
    if cancelled() {
      return
    }
    for _, entry := range dirents(dir) {
      // ...
    }
  }
  func dirents(dir string) []os.FileInfo {
    select {
    case sema <- struct{}{}: // acquire token
    case <-done:
      return nil // cancelled
    }
    defer func() { <-sema }() // release token
    // ...read directory...
  }
#+END_SRC

** 重要的测试技巧

Q : 其实，你自己是很难判断是否把所有的goroutine都关闭并推出了。那么如何在main函数返回的时候，确定还有没有goroutine再运行呢？

A : 在main函数退出之前，调用一个panic，看运行时堆栈信息。如果信息只有main函数的堆栈则说明所有goroutine都退出了。否则，就是说有的goroutine没有退出。

* 聊天服务器

#+BEGIN_SRC go
  func main() {
    listener, err := net.Listen("tcp", "localhost:8000")
    if err != nil {
      log.Fatal(err)
    }
    go broadcaster() // 广播消息
    for {
      conn, err := listener.Accept()
      if err != nil {
        log.Print(err)
        continue 
      }
      go handleConn(conn) // 管理客户端发来的连接
    }
  }
#+END_SRC

#+BEGIN_SRC go
  type client chan<- string // an outgoing message channel
  var (
    entering = make(chan client)
    leaving  = make(chan client)
    messages = make(chan string) // all incoming client messages
  )
  func broadcaster() {
    clients := make(map[client]bool) // all connected clients (chan是可hash的么？)
    for {
      select {
      case msg := <-messages:
        // Broadcast incoming message to all
        // clients' outgoing message channels.
        for cli := range clients {
          cli <- msg
        }
      case cli := <-entering:
        clients[cli] = true
      case cli := <-leaving:
        delete(clients, cli)
        close(cli)
      }
    }
  }
#+END_SRC

#+BEGIN_SRC go
  func handleConn(conn net.Conn) {
    ch := make(chan string) // outgoing client messages
    go clientWriter(conn, ch)
    who := conn.RemoteAddr().String()
    ch <- "You are " + who
    messages <- who + " has arrived"
    entering <- ch
    input := bufio.NewScanner(conn)
    for input.Scan() {
      messages <- who + ": " + input.Text()
    }
    // NOTE: ignoring potential errors from input.Err()
    leaving <- ch
    messages <- who + " has left"
    conn.Close()
  }
  func clientWriter(conn net.Conn, ch <-chan string) {
    for msg := range ch { // 会泄露么？
      fmt.Fprintln(conn, msg) // NOTE: ignoring network errors
    }
  }
#+END_SRC


